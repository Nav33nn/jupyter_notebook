{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11149,
     "status": "ok",
     "timestamp": 1552558311812,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "8edSiHPi2N5l",
    "outputId": "7156054b-01a5-4fc8-a252-a2f41847b5dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "import keras\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "l = 10\n",
    "num_filter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105407,
     "status": "ok",
     "timestamp": 1552558406108,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "-hkvQwOH2cCO",
    "outputId": "ef99c3e6-1052-4541-a2a8-a15b512c10c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 92s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ztoDypc63gEs"
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SNnGm8Tv2fR1"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "\n",
    "# Layer 1\n",
    "layer1 = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input)\n",
    "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
    "layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size=(2, 2))(layer1)\n",
    "\n",
    "# Layer 2\n",
    "layer2 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(layer1)\n",
    "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
    "layer2 = LeakyReLU(alpha=0.1)(layer2)\n",
    "layer2 = MaxPooling2D(pool_size=(2, 2))(layer2)\n",
    "\n",
    "# Layer 3\n",
    "layer3 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(layer2)\n",
    "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
    "layer3 = LeakyReLU(alpha=0.1)(layer3)\n",
    "\n",
    "# Layer 4\n",
    "layer4 = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(layer3)\n",
    "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
    "layer4 = LeakyReLU(alpha=0.1)(layer4)\n",
    "\n",
    "# Layer 5\n",
    "layer5 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(layer4)\n",
    "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
    "layer5 = LeakyReLU(alpha=0.1)(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
    "\n",
    "# Layer 6\n",
    "layer6 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(layer5)\n",
    "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
    "layer6 = LeakyReLU(alpha=0.1)(layer6)\n",
    "\n",
    "# Layer 7\n",
    "layer7 = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(layer6)\n",
    "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
    "layer7 = LeakyReLU(alpha=0.1)(layer7)\n",
    "\n",
    "# Layer 8\n",
    "layer8 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(layer7)\n",
    "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
    "layer8 = LeakyReLU(alpha=0.1)(layer8)\n",
    "layer8 = MaxPooling2D(pool_size=(2, 2))(layer8)\n",
    "\n",
    "# Layer 9\n",
    "layer9 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(layer8)\n",
    "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
    "layer9 = LeakyReLU(alpha=0.1)(layer9)\n",
    "\n",
    "# Layer 10\n",
    "layer10 = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(layer9)\n",
    "layer10 = BatchNormalization(name='norm_10')(layer10)\n",
    "layer10 = LeakyReLU(alpha=0.1)(layer10)\n",
    "\n",
    "# Layer 11\n",
    "layer11 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(layer10)\n",
    "layer11 = BatchNormalization(name='norm_11')(layer11)\n",
    "layer11 = LeakyReLU(alpha=0.1)(layer11)\n",
    "\n",
    "# Layer 12\n",
    "layer12 = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(layer11)\n",
    "layer12 = BatchNormalization(name='norm_12')(layer12)\n",
    "layer12 = LeakyReLU(alpha=0.1)(layer12)\n",
    "\n",
    "skip_connection = layer12\n",
    "\n",
    "# Layer 13\n",
    "layer13 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(layer12)\n",
    "layer13 = BatchNormalization(name='norm_13')(layer13)\n",
    "layer13 = LeakyReLU(alpha=0.1)(layer13)\n",
    "\n",
    "\n",
    "\n",
    "layer13 = MaxPooling2D(pool_size=(2, 2))(layer13)\n",
    "\n",
    "# Layer 14\n",
    "layer14 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(layer13)\n",
    "layer14 = BatchNormalization(name='norm_14')(layer14)\n",
    "layer14 = LeakyReLU(alpha=0.1)(layer14)\n",
    "\n",
    "# Layer 15\n",
    "layer15 = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(layer14)\n",
    "layer15 = BatchNormalization(name='norm_15')(layer15)\n",
    "layer15 = LeakyReLU(alpha=0.1)(layer15)\n",
    "\n",
    "# Layer 16\n",
    "layer16 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(layer15)\n",
    "layer16 = BatchNormalization(name='norm_16')(layer16)\n",
    "layer16 = LeakyReLU(alpha=0.1)(layer16)\n",
    "\n",
    "# Layer 17\n",
    "layer17 = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(layer16)\n",
    "layer17 = BatchNormalization(name='norm_17')(layer17)\n",
    "layer17 = LeakyReLU(alpha=0.1)(layer17)\n",
    "\n",
    "# Layer 18\n",
    "layer18 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(layer17)\n",
    "layer18 = BatchNormalization(name='norm_18')(layer18)\n",
    "layer18 = LeakyReLU(alpha=0.1)(layer18)\n",
    "\n",
    "# Layer 19\n",
    "layer19 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(layer18)\n",
    "layer19 = BatchNormalization(name='norm_19')(layer19)\n",
    "layer19 = LeakyReLU(alpha=0.1)(layer19)\n",
    "\n",
    "# Layer 20\n",
    "layer20 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(layer19)\n",
    "layer20 = BatchNormalization(name='norm_20')(layer20)\n",
    "layer20 = LeakyReLU(alpha=0.1)(layer20)\n",
    "\n",
    "# skip connection layer\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "layer20 = concatenate([skip_connection, layer20])\n",
    "\n",
    "# Layer 21\n",
    "layer21 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(layer20)\n",
    "layer21 = BatchNormalization(name='norm_22')(layer21)\n",
    "layer21 = LeakyReLU(alpha=0.1)(layer21)\n",
    "\n",
    "# Layer 22\n",
    "layer22 = Flatten()(layer21)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(layer22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2737
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1552559132272,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "Jeh0VAxy26NV",
    "outputId": "43274fdc-4a6a-46be-eca9-6f5ad0a2051e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 32, 32, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 32, 32, 32)   128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 32, 32, 32)   0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 32)   0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 16, 16, 64)   18432       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 16, 16, 64)   256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 16, 16, 64)   0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 8, 8, 128)    73728       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 8, 8, 128)    512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 8, 8, 128)    0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 8, 8, 64)     8192        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 8, 8, 64)     256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 64)     0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 8, 8, 128)    73728       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 8, 8, 128)    512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 128)    0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 128)    0           leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 4, 4, 256)    294912      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 4, 4, 256)    1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 4, 4, 256)    0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 4, 4, 128)    32768       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 4, 4, 128)    512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 4, 4, 128)    0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 4, 4, 256)    294912      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 4, 4, 256)    1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 4, 4, 256)    0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 2, 2, 256)    0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 2, 2, 512)    1179648     max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 2, 2, 512)    2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 2, 2, 512)    0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 2, 2, 256)    131072      leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 2, 2, 256)    1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 2, 2, 256)    0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 2, 2, 512)    1179648     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 2, 2, 512)    2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 2, 2, 512)    0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 2, 2, 256)    131072      leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 2, 2, 256)    1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 2, 2, 256)    0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 2, 2, 512)    1179648     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 2, 2, 512)    2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 2, 2, 512)    0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 1, 1, 512)    0           leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 1, 1, 1024)   4718592     max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 1, 1, 512)    524288      leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 1, 1, 512)    2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 1, 1, 512)    0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 1, 1, 1024)   4718592     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 1, 1, 512)    524288      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 1, 1, 512)    2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 1, 1, 512)    0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 1, 1, 1024)   4718592     leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 1, 1, 1024)   9437184     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 2, 2, 64)     16384       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 2, 2, 64)     256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 1, 1, 1024)   9437184     leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 2, 2, 64)     0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 1, 256)    0           leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 1280)   0           lambda_2[0][0]                   \n",
      "                                                                 leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 1, 1, 1024)   11796480    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1024)         0           leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           10250       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,541,802\n",
      "Trainable params: 50,521,130\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "apCwOjvZ4Kts"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4665088,
     "status": "ok",
     "timestamp": 1552563891351,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "tLaFy2AO4TLl",
    "outputId": "414e60e3-2784-413c-a4a3-c693c736a659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 1.2345 - acc: 0.5532 - val_loss: 2.0166 - val_acc: 0.4297\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.9061 - acc: 0.6782 - val_loss: 1.0219 - val_acc: 0.6529\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.7261 - acc: 0.7476 - val_loss: 1.1913 - val_acc: 0.6197\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6190 - acc: 0.7856 - val_loss: 1.1258 - val_acc: 0.6637\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5230 - acc: 0.8190 - val_loss: 1.3136 - val_acc: 0.6245\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4587 - acc: 0.8415 - val_loss: 1.1325 - val_acc: 0.6765\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4102 - acc: 0.8596 - val_loss: 1.1576 - val_acc: 0.6776\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.3433 - acc: 0.8830 - val_loss: 1.1031 - val_acc: 0.6923\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.2750 - acc: 0.9052 - val_loss: 0.9501 - val_acc: 0.7487\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.2397 - acc: 0.9162 - val_loss: 0.8724 - val_acc: 0.7576\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.2004 - acc: 0.9302 - val_loss: 0.9702 - val_acc: 0.7493\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.1740 - acc: 0.9399 - val_loss: 0.8919 - val_acc: 0.7672\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.1544 - acc: 0.9460 - val_loss: 1.0349 - val_acc: 0.7358\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.1363 - acc: 0.9527 - val_loss: 1.1885 - val_acc: 0.7251\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.1188 - acc: 0.9581 - val_loss: 1.0536 - val_acc: 0.7651\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.1081 - acc: 0.9628 - val_loss: 1.1933 - val_acc: 0.7481\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0976 - acc: 0.9663 - val_loss: 0.9204 - val_acc: 0.7862\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0867 - acc: 0.9705 - val_loss: 1.0472 - val_acc: 0.7687\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0900 - acc: 0.9692 - val_loss: 1.1620 - val_acc: 0.7626\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0823 - acc: 0.9707 - val_loss: 0.9730 - val_acc: 0.7869\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0721 - acc: 0.9746 - val_loss: 1.0774 - val_acc: 0.7828\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0703 - acc: 0.9756 - val_loss: 3.9748 - val_acc: 0.6075\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0678 - acc: 0.9770 - val_loss: 1.8242 - val_acc: 0.6803\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.1310 - acc: 0.9560 - val_loss: 0.9857 - val_acc: 0.7649\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0553 - acc: 0.9809 - val_loss: 1.0924 - val_acc: 0.7828\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0538 - acc: 0.9810 - val_loss: 1.2099 - val_acc: 0.7707\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0508 - acc: 0.9826 - val_loss: 1.1811 - val_acc: 0.7610\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0484 - acc: 0.9838 - val_loss: 0.9875 - val_acc: 0.7948\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0515 - acc: 0.9819 - val_loss: 1.0471 - val_acc: 0.7872\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0481 - acc: 0.9835 - val_loss: 1.2217 - val_acc: 0.7602\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0462 - acc: 0.9841 - val_loss: 1.1697 - val_acc: 0.7767\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0453 - acc: 0.9841 - val_loss: 1.2325 - val_acc: 0.7649\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0456 - acc: 0.9850 - val_loss: 1.0953 - val_acc: 0.7829\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0430 - acc: 0.9851 - val_loss: 1.0857 - val_acc: 0.7890\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0405 - acc: 0.9858 - val_loss: 1.1405 - val_acc: 0.7907\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0430 - acc: 0.9853 - val_loss: 1.0552 - val_acc: 0.7879\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0381 - acc: 0.9870 - val_loss: 1.5059 - val_acc: 0.7551\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0437 - acc: 0.9848 - val_loss: 1.3332 - val_acc: 0.7537\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0363 - acc: 0.9875 - val_loss: 1.5102 - val_acc: 0.7248\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0375 - acc: 0.9871 - val_loss: 1.1667 - val_acc: 0.7746\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0340 - acc: 0.9887 - val_loss: 1.1512 - val_acc: 0.7818\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0322 - acc: 0.9892 - val_loss: 1.2227 - val_acc: 0.7708\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0326 - acc: 0.9895 - val_loss: 1.1231 - val_acc: 0.7888\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0337 - acc: 0.9886 - val_loss: 1.0134 - val_acc: 0.8004\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0329 - acc: 0.9890 - val_loss: 1.1942 - val_acc: 0.7831\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0272 - acc: 0.9906 - val_loss: 1.3165 - val_acc: 0.7706\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0486 - acc: 0.9840 - val_loss: 1.1807 - val_acc: 0.7726\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0287 - acc: 0.9898 - val_loss: 1.2075 - val_acc: 0.7650\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0262 - acc: 0.9914 - val_loss: 1.2040 - val_acc: 0.7822\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0256 - acc: 0.9909 - val_loss: 1.1382 - val_acc: 0.7902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91745a8048>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 389318,
     "status": "ok",
     "timestamp": 1552563908594,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "pTfZIGrf4Uyd",
    "outputId": "29055458-2ae9-419c-8cf5-bc660366a301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 938us/step\n",
      "Test loss: 1.1381536527633667\n",
      "Test accuracy: 0.7902\n",
      "Saved the model to disk\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
    "print(\"Saved the model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 131517,
     "status": "ok",
     "timestamp": 1552564481931,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "Jiyb9TlVGsZs",
    "outputId": "c3f3eb71-0cab-4277-f0b5-3758748c7d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('::ffff:127.0.0.1', 46608, 0, 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
      "    method()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
      "    self.copyfile(f, self.wfile)\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
      "    shutil.copyfileobj(source, outputfile)\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
      "    fdst.write(buf)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
    "print(\"Saved the model to disk\")\n",
    "from google.colab import files\n",
    "\n",
    "files.download('Yolo_Basic_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g9A3pesKbUJ8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3B.ipynb",
   "provenance": [
    {
     "file_id": "1riIR_3wcDL1FeIub2kjj0LPdY-ul54EI",
     "timestamp": 1552553705090
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
