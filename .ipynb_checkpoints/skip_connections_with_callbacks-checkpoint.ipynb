{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8edSiHPi2N5l"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "import keras\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "l = 10\n",
    "num_filter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-hkvQwOH2cCO"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ztoDypc63gEs"
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x8(x):\n",
    "    return tf.space_to_depth(x, block_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "t7yZTtFY8VLd"
   },
   "outputs": [],
   "source": [
    "def block(input, count, max_pool = False):\n",
    "  def base_network_block(input_layer, number_of_kernels, count, max_pool ):\n",
    "    output_layer = Conv2D(number_of_kernels, (3,3), strides=(1,1), padding='same', name='conv_'+str(count), use_bias=False)(input_layer)\n",
    "    output_layer = BatchNormalization(name='norm_'+str(count))(output_layer)\n",
    "    output_layer = LeakyReLU(alpha=0.1)(output_layer)\n",
    "    if max_pool:\n",
    "      output_layer = MaxPooling2D(pool_size=(2, 2))(output_layer)\n",
    "    return output_layer, count+1\n",
    "  layer1, count = base_network_block(input, 32, count, max_pool=False)\n",
    "  layer2, count = base_network_block(layer1, 64, count, max_pool=False)\n",
    "  layer3, count = base_network_block(layer2, 128, count, max_pool=False)\n",
    "  layer4, count = base_network_block(layer3, 256, count, max_pool=False)\n",
    "  layer5, count = base_network_block(layer3, 512, count, max_pool=False)\n",
    "  output = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
    "  return output, count, base_network_block\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wUnxrxY_rYP9"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "count = 1\n",
    "\n",
    "\n",
    "block1, count, _ = block(input, count)\n",
    "skip_connection = block1\n",
    "block2, count, _ = block(block1, count)\n",
    "block3, count, _ = block(block2, count)\n",
    "block4, count, _ = block(block3, count)\n",
    "\n",
    "# skip_connection block\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x8)(skip_connection)\n",
    "\n",
    "\n",
    "\n",
    "concat_layer = concatenate([skip_connection, block4])\n",
    "flatten_layer = Flatten()(concat_layer)\n",
    "output = Dense(num_classes, activation='softmax')(flatten_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1552644629031,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "Jeh0VAxy26NV",
    "outputId": "a8be17b2-db27-468b-8d25-fd376527aa13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 32, 32, 32)   864         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 32, 32, 32)   128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_208 (LeakyReLU)     (None, 32, 32, 32)   0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 32, 32, 64)   18432       leaky_re_lu_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 32, 32, 64)   256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_209 (LeakyReLU)     (None, 32, 32, 64)   0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 32, 32, 128)  73728       leaky_re_lu_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 32, 32, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_210 (LeakyReLU)     (None, 32, 32, 128)  0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 32, 32, 512)  589824      leaky_re_lu_210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 32, 32, 512)  2048        conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_212 (LeakyReLU)     (None, 32, 32, 512)  0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 16, 16, 512)  0           leaky_re_lu_212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 16, 16, 32)   147456      max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 16, 16, 32)   128         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_213 (LeakyReLU)     (None, 16, 16, 32)   0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 16, 16, 64)   18432       leaky_re_lu_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 16, 16, 64)   256         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_214 (LeakyReLU)     (None, 16, 16, 64)   0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 16, 16, 128)  73728       leaky_re_lu_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 16, 16, 128)  512         conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_215 (LeakyReLU)     (None, 16, 16, 128)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 16, 16, 512)  589824      leaky_re_lu_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 16, 16, 512)  2048        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_217 (LeakyReLU)     (None, 16, 16, 512)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 8, 8, 512)    0           leaky_re_lu_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 8, 8, 32)     147456      max_pooling2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 8, 8, 32)     128         conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_218 (LeakyReLU)     (None, 8, 8, 32)     0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 8, 8, 64)     18432       leaky_re_lu_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 8, 8, 64)     256         conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_219 (LeakyReLU)     (None, 8, 8, 64)     0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 8, 8, 128)    73728       leaky_re_lu_219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 8, 8, 128)    512         conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_220 (LeakyReLU)     (None, 8, 8, 128)    0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 8, 8, 512)    589824      leaky_re_lu_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 8, 8, 512)    2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_222 (LeakyReLU)     (None, 8, 8, 512)    0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 4, 4, 512)    0           leaky_re_lu_222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 4, 4, 32)     147456      max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 4, 4, 32)     128         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_223 (LeakyReLU)     (None, 4, 4, 32)     0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 4, 4, 64)     18432       leaky_re_lu_223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 4, 4, 64)     256         conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_224 (LeakyReLU)     (None, 4, 4, 64)     0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 4, 4, 128)    73728       leaky_re_lu_224[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 4, 4, 128)    512         conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_225 (LeakyReLU)     (None, 4, 4, 128)    0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 16, 16, 64)   32768       max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 4, 4, 512)    589824      leaky_re_lu_225[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 16, 16, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 4, 4, 512)    2048        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_228 (LeakyReLU)     (None, 16, 16, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_227 (LeakyReLU)     (None, 4, 4, 512)    0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2, 2, 4096)   0           leaky_re_lu_228[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 2, 2, 512)    0           leaky_re_lu_227[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2, 2, 4608)   0           lambda_11[0][0]                  \n",
      "                                                                 max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 18432)        0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           184330      flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,400,298\n",
      "Trainable params: 3,394,282\n",
      "Non-trainable params: 6,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "apCwOjvZ4Kts"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4422,
     "status": "ok",
     "timestamp": 1552645008368,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "9KvKGrIt2oVS",
    "outputId": "cb73ead9-17f5-4c98-92d3-dbf34d4e8302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  Yolo_Basic_model2.h5\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3451
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8395567,
     "status": "ok",
     "timestamp": 1552653460699,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "tLaFy2AO4TLl",
    "outputId": "d991dd84-0b41-4d71-c7cd-2c3adc92b72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.9542 - acc: 0.6703 - val_loss: 1.0744 - val_acc: 0.6431\n",
      "\n",
      "Epoch 00001: saving model to cp.ckpt\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.7744 - acc: 0.7320 - val_loss: 1.2006 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00002: saving model to cp.ckpt\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.6549 - acc: 0.7722 - val_loss: 1.1735 - val_acc: 0.6427\n",
      "\n",
      "Epoch 00003: saving model to cp.ckpt\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.5611 - acc: 0.8047 - val_loss: 1.9393 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00004: saving model to cp.ckpt\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.4636 - acc: 0.8403 - val_loss: 1.1050 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00005: saving model to cp.ckpt\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.3791 - acc: 0.8684 - val_loss: 1.1162 - val_acc: 0.6834\n",
      "\n",
      "Epoch 00006: saving model to cp.ckpt\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.2992 - acc: 0.8967 - val_loss: 1.2633 - val_acc: 0.6690\n",
      "\n",
      "Epoch 00007: saving model to cp.ckpt\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.2235 - acc: 0.9239 - val_loss: 1.3228 - val_acc: 0.6777\n",
      "\n",
      "Epoch 00008: saving model to cp.ckpt\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 176s 4ms/step - loss: 0.1707 - acc: 0.9426 - val_loss: 1.2129 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00009: saving model to cp.ckpt\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.1286 - acc: 0.9561 - val_loss: 1.2219 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00010: saving model to cp.ckpt\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.1081 - acc: 0.9635 - val_loss: 1.4056 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00011: saving model to cp.ckpt\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.0970 - acc: 0.9669 - val_loss: 1.4932 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00012: saving model to cp.ckpt\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.0827 - acc: 0.9721 - val_loss: 1.5519 - val_acc: 0.7067\n",
      "\n",
      "Epoch 00013: saving model to cp.ckpt\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 169s 3ms/step - loss: 0.0722 - acc: 0.9755 - val_loss: 1.8910 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00014: saving model to cp.ckpt\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0832 - acc: 0.9710 - val_loss: 1.7273 - val_acc: 0.6907\n",
      "\n",
      "Epoch 00015: saving model to cp.ckpt\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0829 - acc: 0.9709 - val_loss: 1.8578 - val_acc: 0.6625\n",
      "\n",
      "Epoch 00016: saving model to cp.ckpt\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 188s 4ms/step - loss: 0.0540 - acc: 0.9822 - val_loss: 1.5259 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00017: saving model to cp.ckpt\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0339 - acc: 0.9892 - val_loss: 1.5839 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00018: saving model to cp.ckpt\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0483 - acc: 0.9842 - val_loss: 1.7691 - val_acc: 0.7088\n",
      "\n",
      "Epoch 00019: saving model to cp.ckpt\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0840 - acc: 0.9705 - val_loss: 1.9885 - val_acc: 0.6825\n",
      "\n",
      "Epoch 00020: saving model to cp.ckpt\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0607 - acc: 0.9782 - val_loss: 1.9950 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00021: saving model to cp.ckpt\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0310 - acc: 0.9898 - val_loss: 1.6981 - val_acc: 0.7145\n",
      "\n",
      "Epoch 00022: saving model to cp.ckpt\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 2.1224 - val_acc: 0.6829\n",
      "\n",
      "Epoch 00023: saving model to cp.ckpt\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0414 - acc: 0.9857 - val_loss: 1.8862 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00024: saving model to cp.ckpt\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0670 - acc: 0.9761 - val_loss: 1.9947 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00025: saving model to cp.ckpt\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0422 - acc: 0.9854 - val_loss: 1.9603 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00026: saving model to cp.ckpt\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 1.8889 - val_acc: 0.7085\n",
      "\n",
      "Epoch 00027: saving model to cp.ckpt\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0290 - acc: 0.9898 - val_loss: 2.0299 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00028: saving model to cp.ckpt\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0457 - acc: 0.9842 - val_loss: 1.9530 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00029: saving model to cp.ckpt\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0497 - acc: 0.9823 - val_loss: 2.3013 - val_acc: 0.6791\n",
      "\n",
      "Epoch 00030: saving model to cp.ckpt\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0302 - acc: 0.9897 - val_loss: 2.0090 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00031: saving model to cp.ckpt\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 1.9494 - val_acc: 0.7148\n",
      "\n",
      "Epoch 00032: saving model to cp.ckpt\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.0209 - acc: 0.9931 - val_loss: 2.0704 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00033: saving model to cp.ckpt\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0502 - acc: 0.9829 - val_loss: 2.0627 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00034: saving model to cp.ckpt\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0364 - acc: 0.9871 - val_loss: 2.2470 - val_acc: 0.6976\n",
      "\n",
      "Epoch 00035: saving model to cp.ckpt\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0269 - acc: 0.9904 - val_loss: 2.7761 - val_acc: 0.6612\n",
      "\n",
      "Epoch 00036: saving model to cp.ckpt\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0205 - acc: 0.9933 - val_loss: 2.0509 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00037: saving model to cp.ckpt\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0160 - acc: 0.9945 - val_loss: 2.2504 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00038: saving model to cp.ckpt\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0296 - acc: 0.9898 - val_loss: 2.3466 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00039: saving model to cp.ckpt\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0334 - acc: 0.9880 - val_loss: 2.0015 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00040: saving model to cp.ckpt\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0302 - acc: 0.9890 - val_loss: 2.1547 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00041: saving model to cp.ckpt\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0236 - acc: 0.9918 - val_loss: 2.1001 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00042: saving model to cp.ckpt\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0139 - acc: 0.9954 - val_loss: 2.1826 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00043: saving model to cp.ckpt\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0202 - acc: 0.9931 - val_loss: 2.1440 - val_acc: 0.7126\n",
      "\n",
      "Epoch 00044: saving model to cp.ckpt\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0233 - acc: 0.9918 - val_loss: 2.2846 - val_acc: 0.7088\n",
      "\n",
      "Epoch 00045: saving model to cp.ckpt\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0311 - acc: 0.9894 - val_loss: 2.3046 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00046: saving model to cp.ckpt\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0267 - acc: 0.9905 - val_loss: 2.2295 - val_acc: 0.7124\n",
      "\n",
      "Epoch 00047: saving model to cp.ckpt\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0131 - acc: 0.9955 - val_loss: 2.1397 - val_acc: 0.7241\n",
      "\n",
      "Epoch 00048: saving model to cp.ckpt\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 2.2413 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00049: saving model to cp.ckpt\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.0283 - acc: 0.9902 - val_loss: 2.3274 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00050: saving model to cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2709468940>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "checkpoint_path = \"cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7969523,
     "status": "ok",
     "timestamp": 1552653472174,
     "user": {
      "displayName": "Naveen Bharadwaj",
      "photoUrl": "https://lh4.googleusercontent.com/-yYj6SAmNV4o/AAAAAAAAAAI/AAAAAAAAAE0/TU_U_ezgx44/s64/photo.jpg",
      "userId": "14707737005437864614"
     },
     "user_tz": -330
    },
    "id": "pTfZIGrf4Uyd",
    "outputId": "ec32ae99-0ad9-4b10-8799-ca81ae5442bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test loss: 2.327448720550537\n",
      "Test accuracy: 0.7034\n",
      "Saved the model to disk\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
    "print(\"Saved the model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jiyb9TlVGsZs"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive \n",
    "from google.colab import auth \n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()   \n",
    "drive = GoogleDrive(gauth)\n",
    "model.save('model.h5')\n",
    "model_file = drive.CreateFile({'title' : 'model.h5'})\n",
    "model_file.SetContentFile('model.h5')\n",
    "model_file.Upload()\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('Yolo_Basic_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g9A3pesKbUJ8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3C.ipynb",
   "provenance": [
    {
     "file_id": "1riIR_3wcDL1FeIub2kjj0LPdY-ul54EI",
     "timestamp": 1552553705090
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
